\documentclass[a4paper, 11pt]{article}

%% packages
\usepackage{fullpage} % changes the margin
\usepackage{hyperref} % Links
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{proof}
\usepackage{braket}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{quantikz}
\usepackage[linewidth=1pt]{mdframed}
%%

%% environments
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{examples}{Example}
\newtheorem{exercises}{Exercises}
\newtheorem{exercise}{Exercise}
\newtheorem{postulate}{Postulate}
\newtheorem{problem}{Problem}
%%

%% config
\date{Winter 2024/25}
\linespread{1.15}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\input{macros}
%%

\begin{document}

\allowdisplaybreaks[2]
\title{\large{Semantics of Programming Languages}
        \\ \large{University of Minho} 
}

\author{\small{Renato Neves} \small
(\href{mailto:nevrenato@di.uminho.pt}{nevrenato@di.uminho.pt})}
\maketitle

\begin{abstract}
This handout briefly summarises our previous lectures and presents related
problems.  It addresses the three styles of semantics that we have studied so
far: namely operational, denotational, and axiomatic semantics.
\end{abstract}

\section{Operational Semantics}

        We started our lectures with the following very simple propositional
        language.
        \[
                \prog{b} ::= \prog{x} \mid \prog{b} \wedge \prog{b} \mid \neg \prog{b}
        \]
        (recall that $\prog{x}$ denotes a variable from a given stock of
        variables).  We established a corresponding (small-step)
        operational semantics, which is detailed in Figure~\ref{fig:small1}.
        %
        \begin{figure}[h]
        \begin{minipage}{1\textwidth}
        \begin{flalign*}
                \infer[(\text{var})]{\langle \mathtt{x}, \sigma \rangle 
                \longrightarrow \sigma(\mathtt{x})}{} \qquad \qquad
                %
                \hspace{2cm}
                %
                \infer[(\text{neg$_1$})]{\langle \neg \prog{b}, \sigma \rangle 
                \longrightarrow \neg v}{
                   \pv{\prog{b}}{\sigma} \longrightarrow
                   v
                }
        \end{flalign*}
        %%
        \\[-30pt]
        %%
        \begin{flalign*}
                \infer[(\text{neg$_2$})]{
                \pv{\neg \prog{b}}{\sigma} 
                \longrightarrow \pv{\neg \prog{b'}}{\sigma'}
                }{
                \pv{\prog{b}}{\sigma} 
                \longrightarrow \pv{\prog{b'}}{\sigma'}
                } 
                %
                \hspace{2cm}
                %
                \infer[(\text{and$_1$})]{
                        \pv{\prog{b_1} \wedge \prog{b_2} }{\sigma}
                \longrightarrow \prog{ff}}{
                   \pv{\prog{b_1}}{\sigma} \longrightarrow
                   \prog{ff}
                }
        \end{flalign*}
        %%
        \\[-30pt]
        %%
        \begin{flalign*}
                %
                \infer[(\text{and$_2$})]{
                %
                \pv{ \prog{b_1} \wedge \prog{b_2} }{ \sigma }
                \longrightarrow 
                \pv{ \prog{b_2} }{\sigma}  }
                {
                   \pv{\prog{b_1}}{\sigma} \longrightarrow
                   \prog{tt}
                }
                %
                \hspace{2cm}
                %
                \infer[(\text{and$_3$})]{
                        \pv{\prog{b_1} \wedge \prog{b_2} }{\sigma}
                \longrightarrow \pv{\prog{b_1'} \wedge \prog{b_2}}{\sigma'} }{
                   \pv{\prog{b_1}}{\sigma} \longrightarrow
                   \pv{\prog{b_1'}}{\sigma'}
                }
        \end{flalign*}
        \end{minipage}
        \label{small_prop}
        \caption{Small-step operational semantics for the propositional language}
        \label{fig:small1}
        \end{figure}

        Observe the `short-circuit' evaluation mechanism present in Rule~(and$_1$), an
        apparent feature in the small-step semantics that becomes somewhat invisible in
        all other semantics that we studied.
        \begin{problem}
                It makes sense to add an `implication construct' $\prog{b}
                \Rightarrow \prog{b}$ to the simple language. Describe which semantic
                rules would you add to Figure~\ref{fig:small1} in order to
                cover this new operation.
        \end{problem}

        One observation from the lectures is that our small-step operational
        semantics is able to describe all computational steps performed by a
        program until it reaches an output. The semantics thus provides an
        interesting abstraction level for talking about `program complexity'.
        In order to drive this point home, in the lectures we defined a
        `complexity function'
        \begin{align*}
                \mathrm{compl}(\prog{x}) & = 1  \\
                \mathrm{compl}(\prog{\neg b}) & = \mathrm{compl}(\prog{b}) \\
                \mathrm{compl}(\prog{b}_1 \wedge \prog{b}_2) & =
                \mathrm{compl}(\prog{b}_1) + \mathrm{compl}(\prog{b}_2)
        \end{align*}
        which intends to present an upper bound to the number of required steps
        for a proposition to be fully evaluated. Of course we still need to
        formally relate it to the small-step semantics and such is the topic of
        the following problem.

        \begin{problem}
                Show by induction (on the syntactic structure of propositions)
                that $\mathrm{compl}(\prog{b}) \geq 1$ for every $\prog{b}$.
                Next, show by induction (over the depth of derivation trees)
                that the implication below holds for all propositions
                $\prog{b}$ and $\prog{b'}$ and any memory $\sigma$.
                \[
                        \text{ If }\pv{\prog{b}}{\sigma} \longrightarrow
                        \pv{\prog{b'}}{\sigma}
                        \text{ then } \mathrm{compl}(\prog{b}) > \mathrm{compl}(\prog{b'})
                \]
        \end{problem}

        Next, recall the grammars of arithmetic expressions and while-programs
        that were studied throughout the lectures: they were defined as
        follows
        \[
                \prog{e} ::=  \mathtt{n}  \mid \mathtt{e \cdot e}
                \mid  \mathtt{x}  \mid \mathtt{e + e}
        \]
        \[
                \prog{p} ::= \mathtt{x} := \mathtt{e} \mid
        	\mathtt{p \> \blue{;} \> p} \mid
        	\mathtt{\blue{if} \> b \> \blue{then} \> p \> \blue{else} \> p} \mid
        	\mathtt{\blue{while} \> b \> \blue{do} \> \{ \> p \> \}}
        \]
        where $\mathtt{n}$ is any natural number.
        \begin{problem}
                Remarkably in the lectures we did not see a small-step
                operational semantics for arithmetic expressions. Can you
                define one such semantics now?
        \end{problem}

        What we did see however was a small-step operational semantics for the while-language,
        which is now detailed in Figure~\ref{fig:small2}.
        \begin{figure}[h]
        \begin{minipage}{1\textwidth}
        \begin{flalign*}
                \infer[(\text{asg})]{
                        \langle \mathtt{x := e}, \sigma \rangle \longrightarrow
                        \sigma[\mathtt{v} / \mathtt{x}]
                }{
                        \langle \mathtt{e}, \sigma \rangle \longrightarrow^\star \mathtt{v}
                } \hspace{2cm}
                \infer[(\text{seq$_1$})]{
                        \langle \mathtt{p \> \blue{;} \> q}, \sigma \rangle \longrightarrow 
                        \pv{\prog{q}}{\sigma'}
                }{
                        \langle \mathtt{p}, \sigma \rangle \longrightarrow \sigma'
                }
        \end{flalign*}
        %%
        \\[-30pt]
        %%
        \begin{flalign*}
                \infer[(\text{seq$_2$})]{
                        \langle \mathtt{p \> \blue{;} \> q}, \sigma \rangle \longrightarrow 
                        \pv{\prog{p' \> \blue{;} \> q}}{\sigma'}
                }{
                        \langle \mathtt{p}, \sigma \rangle 
                        \longrightarrow \pv{\prog{p'}}{\sigma'}
                }
                \hspace{2cm}
                \infer[(\text{if$_1$})]{
                        \langle \mathtt{\blue{if} \> b \> \blue{then} \> \> 
                        p \> \blue{else} \> q}, 
                        \sigma \rangle \longrightarrow \pv{\prog{p}}{\sigma}
                }{
                        \langle \mathtt{b}, \sigma \rangle \longrightarrow^\star \mathtt{tt} 
                } 
        \end{flalign*}
        %%
        \\[-30pt]
        %%
        \begin{flalign*}
                \infer[(\text{if$_2$})]{
                        \langle \mathtt{\blue{if} \> b \> \blue{then} \> \> 
                        p \> \blue{else} \> q}, 
                        \sigma \rangle \longrightarrow \pv{\prog{q}}{\sigma}
                }{
                        \langle \mathtt{b}, \sigma \rangle \longrightarrow^\star \mathtt{ff} 
                } 
                \hspace{2cm}
                \infer[(\text{wh$_2$})]{
                        \langle 
                        \mathtt{\blue{while} \> b \> \blue{do} \> \{ \> p \> \}}, \sigma \rangle
                        \longrightarrow^\star \sigma
                }{
                        \langle \mathtt{b}, \sigma \rangle \longrightarrow^\star \mathtt{ff}
                }
        \end{flalign*}
        %%
        \\[-30pt]
        %%
        \begin{flalign*}
                \infer[(\text{wh$_1$})]{
                        \langle \mathtt{\blue{while} \> b \> \blue{do} \> \{ \> p \> \}}, 
                        \sigma \rangle
                        \longrightarrow 
                        \pv{\prog{p} \> \blue{;} \> 
                        \mathtt{\blue{while} \> b \> \blue{do} \> \{ \> p \> \}}}{
                        \sigma}
                }{
                        \pv{\prog{b}}{\sigma} \longrightarrow^\star \prog{tt} 
                }
        \end{flalign*}
        \end{minipage}
        \caption{A small-step operational semantics for the while-language.}
        \label{fig:small2}
        \end{figure}

        \begin{problem}
                Thus explain the meaning of the notation $\longrightarrow^\star$.
        \end{problem}

        Great, now that we have a semantics (and that we understand it) we can
        use it to derive the chain of transitions that is generated by a
        program until it reaches an output. This is particularly useful for
        \emph{debugging} and for studying non-terminating behaviours, among
        other things.
        \begin{problem}
                \label{prob:out}
                Calculate via the semantics in Figure~\ref{fig:small2} the
                chains of transitions that arise from the following programs.
                \begin{itemize}
                        \item 
                        $\prog{ x := 1} \> \blue{;} \> \prog{x := 2}$
                \item                         $\prog{ \blue{if} } 
                        \>  \prog{tt}  \> \prog{ \blue{then}}  \>
                        (\prog{ x := 1} \> \blue{;} \> \prog{x := 2})
                        \>  \prog{ \blue{else}}
                        \> \> \prog{ x := 3 }$
                \end{itemize}
                Give an example of a program that generates an \emph{infinite}
                sequence of transitions. Justify your choice mathematically
                :-).
        \end{problem}


We now lean over our big-step operational semantics. Recall that it abstracts
away from all intermediate computational steps performed in the context of the
small-step semantics. It is therefore better suited than the latter for
calculating outputs and for studying program equivalence (among other things).
The big-step semantics of our while-language is defined in
Figure~\ref{fig:big}.

        \begin{figure}[h]
        \begin{minipage}{1\textwidth}
        \begin{flalign*}
                \infer[(\text{asg})]{
                        \langle \mathtt{x := e}, \sigma \rangle \Downarrow 
                        \sigma[\mathtt{v} / \mathtt{x}]
                }{
                       \langle \mathtt{e}, \sigma \rangle \Downarrow \mathtt{v}
                } 
                \hspace{2cm}
                \infer[(\text{seq})]{
                        \langle \mathtt{p \> \blue{ ;} \> q}, \sigma \rangle \Downarrow \sigma''
                }{
                        \langle \mathtt{p}, \sigma \rangle \Downarrow \sigma' \qquad
                        \langle \mathtt{q}, \sigma' \rangle \Downarrow \sigma'' 
                }
        \end{flalign*}
        %%
        \\[-30pt]
        %%
        \begin{flalign*}
                \infer[(\text{if$_1$})]{
                        \langle \mathtt{\blue{ if} \> b \> \blue{ then} \> \> p \> \blue{ else} \> q}, 
                        \sigma \rangle \Downarrow \sigma'
                }{
                        \langle \mathtt{b}, \sigma \rangle \Downarrow \mathtt{tt} \qquad
                        \langle \mathtt{p}, \sigma \rangle \Downarrow \sigma'
                } 
                %
                \hspace{2cm} 
                %
                \infer[(\text{if$_2$})]{
                        \langle \mathtt{\blue{ if} \> b \> \blue{ then} \> \> p \> \blue{ else} \> q}, 
                        \sigma \rangle \Downarrow \sigma'
                }{
                        \langle \mathtt{b}, \sigma \rangle \Downarrow \mathtt{ff} \qquad
                        \langle \mathtt{q}, \sigma \rangle \Downarrow \sigma'
                } 
        \end{flalign*}
        %%
        \\[-30pt]
        %%
        \begin{flalign*}
                \infer[(\text{wh$_1$})]{
                        \langle \mathtt{\blue{ while} \> b \> \blue{ do} \> \{ \> p \> \}}, \sigma \rangle
                        \Downarrow \sigma''
                }{
                        \langle \mathtt{b}, \sigma \rangle \Downarrow \mathtt{tt} \qquad
                        \langle \mathtt{p}, \sigma \rangle \Downarrow \sigma' \qquad
                        \langle \mathtt{\blue{ while} \> b \> \blue{ do} \> \{ \> p \> \}}, \sigma'
                        \rangle \Downarrow \sigma'' 
                }
        \end{flalign*}
        %%
        \\[-30pt]
        %%
        \begin{flalign*}
                \infer[(\text{wh$_2$})]{
                        \langle \mathtt{\blue{ while} \> b \> \blue{ do} \> \{ \> p \> \}}, \sigma \rangle
                        \Downarrow \sigma
                }{
                        \langle \mathtt{b}, \sigma \rangle \Downarrow \mathtt{ff}
                }
        \end{flalign*}
        \end{minipage}
        \caption{A big-step operational semantics for the while-language.}
        \label{fig:big}
        \end{figure}
\begin{problem}
        In the lectures we did not see a big-step operational semantics for
        arithmetic expressions. Can you define one such semantics now?
\end{problem}

As already mentioned, the big-step semantics differs from the small-step
counterpart in that it abstracts away from all intermediate computational
steps. This renders output calculation conceptually different than the one
performed in Problem~\eqref{prob:out}. Let us try to make such differences more
evident and palpable with the following problem. 

\begin{problem}
Calculate via the semantics in Figure~\ref{fig:big} the outputs of the two
programs below.
                \begin{itemize}
                        \item 
                        $\prog{ x := 1} \> \blue{;} \> \prog{x := 2}$
                \item                         $\prog{ \blue{if} } 
                        \>  \prog{tt}  \> \prog{ \blue{then}}  \>
                        (\prog{ x := 1} \> \blue{;} \> \prog{x := 2})
                        \>  \prog{ \blue{else}}
                        \> \> \prog{ x := 3 }$
                \end{itemize}
Reflect on the differences between calculating the outputs of these two
programs with respect to the small-step semantics and big-step semantics.
Finally check whether for every program $\prog{p}$ and memory $\sigma$ we
always have $\pv{\prog{p}}{\sigma} \Downarrow \sigma'$ for some memory
$\sigma'$.
\end{problem} 

Right, now that we have two different, complementary semantics for our
while-language (small-step and big-step semantics) it makes sense to prove that
they `agree' with each other, more formally that the equivalence below holds
       \[
                \pv{\prog{p}}{\sigma} \longrightarrow^\star \sigma'
                \text{ iff } \pv{\prog{p}}{\sigma} \Downarrow \sigma'
       \]
for every program $\prog{p}$ and every state $\sigma$ and $\sigma'$. We will
focus on proving just the left-to-right direction of this equivalence.
\begin{problem}
       Consider programs $\prog{p}$ and $\prog{p'}$ and states
       $\sigma,\sigma',\sigma''$. Prove by induction (over the depth of
       derivation trees) the following implication.
       \[
               \pv{\prog{p}}{\sigma} \longrightarrow \pv{\prog{p'}}{\sigma'}
               \Downarrow \sigma'' \text{ implies } \pv{\prog{p}}{\sigma} \Downarrow \sigma''
       \]
       Then use this last result to prove the implication below.
       \[
                \pv{\prog{p}}{\sigma} \longrightarrow^\star \sigma'
                \text{ implies } \pv{\prog{p}}{\sigma} \Downarrow \sigma'
       \]
\end{problem}

So as mentioned before the big-step semantics provides an interesting
abstraction level for reasoning about program equivalence.  In this regard, we
started by considering the following tentative notion: two programs $\prog{p}$
and $\prog{q}$ will be equivalent (in symbols $\prog{p} \equiv_o \prog{q}$) if
the equivalence below holds.
       \[
                \pv{\prog{p}}{\sigma} \Downarrow \sigma'
                \text{ iff } \pv{\prog{q}}{\sigma} \Downarrow \sigma'
                \hspace{2.5cm} (\text{for all states } \sigma,\sigma')
       \]
Let us thus see if we can establish some interesting program equivalences.
\begin{problem}
        The two equivalences propounded below are tacitly used by programmers
        virtually all the time (even if only a few can prove them). Use the
        big-step semantics to show that these equivalences are indeed correct.
        \begin{itemize}
                \item $\mathtt{(p \> \blue{ ;} \> q) \> {\blue ;} \> r} \equiv_o
                        \mathtt{p \> \blue{ ;} \> (q \> {\blue ;} \> r)}$
                \item $\mathtt{(\blue{ if} \> b \> \blue{ then} \> p \> \blue{ else} \> q) 
                      \> \blue{ ;} \> \prog{r}} \equiv_o 
                      \mathtt{\blue{ if} \> b \> \blue{ then} \> p \> \blue{ ;} \> r \> 
                      \blue{ else} \> q \> \blue{ ;} \> r}$ 
        \end{itemize}
\end{problem}

Next let us recall our second (and definite) notion  of program equivalence --
the one that compilers typically adopt. As mentioned in lectures it is referred
to as \emph{contextual equivalence} and recurs to the following grammar of
`contexts'.
\[              
                C ::= [-] \mid C \> \prog{ \blue{;}} \> \prog{p} 
                \mid 
                \prog{p} \> \prog{ \blue{;}} \> C 
                \mid 
                \mathtt{\blue{ if} \> b \> \blue{ then} \>} C \mathtt{\> \blue{ else} \> p} 
                \mid
                \mathtt{\blue{ if} \> b \> \blue{ then} \>} \prog{p} \mathtt{\> \blue{ else} \> C} 
                \mid
                \mathtt{\blue{ while} \> b \> \blue{ do} \> \{ \>} C \mathtt{\> \}}
\]
Two programs $\prog{p}$ and $\prog{q}$ will be contextually equivalent (in
symbols $\prog{p} \equiv \prog{q}$) if the equivalence below holds.
\[
               \pv{C[\prog{p}]}{\sigma} \Downarrow \sigma'
               \text{ iff } \pv{C[\prog{q}]}{\sigma} \Downarrow \sigma'
               \hspace{2.5cm} (\text{for all states } \sigma,\sigma' \text{ and contexts } C)
\]
\begin{problem}
        Reflect on why compilers use the notion of contextual equivalence and not the
        previous one (\ie\ $\equiv_o$).
\end{problem}
\begin{problem}
        \label{prob:equiv}
        The natural question then arises of whether the equivalence below holds
        \[
                \prog{p} \equiv \prog{q} \text{ iff } \prog{p} \equiv_o \prog{q} 
        \]
        for all programs $\prog{p}$ and $\prog{q}$.  The left-to-right
        direction is clear, but what about the inverse direction?  Can you
        prove it? Where do you get stuck?
\end{problem}

\section{Denotational Semantics}

We now focus on the denotational semantics of the previous lectures.  Not only
it helped us with Problem~\eqref{prob:equiv}, it also allowed us to `import'
knowledge from other mathematical theories (\eg\ `program calculus'). 

A main challenge of this semantics was the interpretation of while-loops which
required us to touch (even if just barely) on the surface of Domain theory.  We
start from this end, in particular with the notion of a partially ordered set
(poset).
\begin{problem}
        Consider a set $\mathrm{State}$ of states. Show that it is a poset when
        equipped with equality as the partial order. Assuming that $\Pow(-)$
        denotes the \emph{powerset construct}, show that the pair $(\Pow
        (X),\subseteq)$ (for any given set $X$) is a poset.

        Next recall that given any poset $(X, \leq_X)$ we were able to define a
        new poset $(X_\bot, \leq)$. Prove that the latter is indeed a
        poset.  Finally given two sets $X$ and $Y$ prove that the set $[X,Y]$
        of maps between $X$ and $Y$ is a poset whenever $Y$ is a poset.
\end{problem}

Let us now go beyond posets and shift our attention to $\omega$-CPOs (\ie\
$\omega$-complete partially ordered sets). We start by revisiting the previous
problem from the latter's perspective.

\begin{problem}
        Consider a set $\mathrm{State}$ of states. Show that it is an
        $\omega$-CPO when equipped with equality as the partial order.  Show as
        well that the pair $(\Pow (X),\subseteq)$ (for any given set $X$) is an
        $\omega$-CPO.

        Next, recall that given any $\omega$-CPO $(X, \leq_X)$ we were able to
        define a new $\omega$-CPO $(X_\bot, \leq)$. Prove that the latter is
        indeed an $\omega$-CPO.  Finally given two sets $X$ and $Y$ prove that
        the set $[X,Y]$ of maps between $X$ and $Y$ is an $\omega$-CPO whenever
        $Y$ is an $\omega$-CPO.
\end{problem}

Another key notion for defining the interpretation of while-loops is that of a
\emph{continuous} map $f : X \to Y$ (between $\omega$-CPOs $X$ and $Y$). Recall
that a map $f$ is called continuous if it satisfies the conditions below.
\begin{flalign*}
        x_1 \leq x_2  & \text{ entails } f(x_1) \leq f(x_2) \qquad (\text{for all $x_1,x_2 \in X$ })
        \\
        f(\vee_{n \in \Nats} \, x_n) & = \vee_{n \in \Nats} \, f(x_n) \qquad \qquad \quad \> \, 
        (\text{for every monotone sequence $(x_n)_{n \in \Nats}$}) 
\end{flalign*}

\begin{problem}
        Prove that the composition $g \comp f : X \to Z$ of continuous maps
        $f : X \to Y$ and $g : Y \to Z$ is continuous.
\end{problem}

These last three problems contain basic ingredients to interpret while-loops as
fixpoints. Another basic ingredient is \emph{Kleene's fixpoint theorem} which
tells how to build the least fixpoint of a continuous map $f : X \to X$ on an
$\omega$-CPO $X$ with a bottom element ($\bot$). Recall that the fixpoint is
denoted by $\mathrm{lfp}\, f$ and explicitly built as,
\[
        \mathrm{lfp}\, f = \vee_{n \in \Nats}\, f^n(\bot)
\]
\begin{problem}
        Show that $\mathrm{lfp}\, f$ is indeed the least fixpoint of $f$.
\end{problem}
Finally after some investments on Domain theory we were able to neatly establish
the denotational semantics of our while-language, detailed in
Figure~\ref{fig:denot}.
\begin{figure}[h]
\begin{minipage}{1\textwidth}
\begin{flalign*}
        \sem{\prog{x : = e}} & = \sigma \mapsto \sigma[\sem{\prog{e}}/\prog{x}] \\[2pt]
        \sem{\prog{p} \> \blue{ ;} \> \prog{q}} & 
        = \sem{\prog{q}} \comp \sem{\prog{p}} \\[5pt]
        \sem{\mathtt{\blue{ if} \> b \> \blue{ then} \> p \> \blue{ else} \> q}}
                                                & 
                                                = [\sem{\prog{p}},\sem{\prog{q}}] \comp
                                                \mathrm{dist} \comp \pv{\sem{\prog{b}}}{\id}
                                                \\[5pt]
        \sem{\mathtt{\blue{ while} \> b \> \blue{ do } \> \{ \> p \> \}} }
                                                & \> {=} \> \mathrm{lfp}\ \Big (k \mapsto
        [k \comp 
        \sem{\prog{p}},\id] \comp
        \mathrm{dist} \comp \pv{\sem{\prog{b}}}{\id} \Big )
\end{flalign*}
\end{minipage}
\caption{A denotational semantics for the while-language.}
\label{fig:denot}
\end{figure}

\begin{problem}
        Although used in the new semantics of our while-language
        (Figure~\ref{fig:denot}) in the lectures we did not see a denotational
        semantics for arithmetic expressions. Can you define one such semantics
        now?
\end{problem}

Great! We now have three different, complementary semantics for our
while-language (\emph{viz.} small-step, big-step, and denotational). It is therefore useful
to prove that they all `agree' with each other. But in fact we just need to relate
the new semantics with the big-step version, for we have already established a
connection between the latter and the small-step semantics. Technically we
achieve this desired connection by proving the equivalence below 
      \begin{align}
              \label{eq:equiv2}
              \pv{\prog{p}}{\sigma} \Downarrow \sigma' \text{ iff }
              \sem{\prog{p}}(\sigma) = \sigma' 
      \end{align}
for every program $\prog{p}$ and states $\sigma,\sigma'$.  We will focus on
proving just the left-to-right direction of this  equivalence.
\begin{problem}
       Consider programs $\prog{p}$ and $\prog{p'}$ and states
       $\sigma,\sigma'$. Prove by induction (over the depth of
       derivation trees) the following implication.
       \[
               \pv{\prog{p}}{\sigma}
               \Downarrow \sigma' \text{ implies } \sem{\prog{p}}(\sigma) = \sigma' 
       \]
       (Hint: Use the fixpoint equation that you learned in lectures).
\end{problem}

From Equivalence~\eqref{eq:equiv2} between the denotational and big-step semantics
we easily establish that for all programs $\prog{p}$ and $\prog{q}$ the
following equivalence holds.
\[
        \prog{p} \equiv_o \prog{q} \text{ iff } \sem{\prog{p}} = \sem{\prog{q}}
\]
But we also want to learn more about the notion of contextual equivalence
($\equiv$). Recall for example that in Problem~\eqref{prob:equiv} we were not
able to show whether $\prog{p} \equiv_o \prog{q}$ entails $\prog{p} \equiv
\prog{q}$. Can denotational semantics help us in this quest?

\begin{problem}
        Consider two programs $\prog{p}$ and $\prog{q}$. Prove via induction on
        the syntactic structure of programs that the following implication
        holds.  
        \[
                \sem{\prog{p}} = \sem{\prog{q}} \text{ entails }
                \Big ( \text{for all contexts } C. \,
                \sem{C[\prog{p}]} = \sem{C[\prog{q}]} \Big )
        \]
\end{problem}

Perfect, we established that contextual equivalence (which quantifies over
infinitely many contexts) reduces to simple \emph{equality} of denotations! We
can thus use our denotational semantics (and all mathematical theories it
inherits, such as `program calculus') to prove equivalences used by programmers
and compilers all the time.

\begin{problem}
        Prove that the following equivalences indeed hold.
        \begin{itemize}
                \item $\mathtt{(p \> \blue{ ;} \> q) \> \blue{ ;} \> r} \equiv
                        \mathtt{p \> \blue{ ;} \> (q \> \blue{ ;} \> r)}$
                \item $\mathtt{(\blue{if} \> b \> \blue{then} \> p \> \blue{else} \> q) 
                      \> \blue{ ;} \> \prog{r}} \equiv 
                      \mathtt{\blue{ if} \> b \> \blue{then} \> p \> \blue{ ;} \> r \> 
                      \blue {else} \> q \> \blue {;} \> r}$ 
              \item $\mathtt{\blue {while} \> b \> \{ p \} } \equiv
                        \mathtt{\blue{if} \> b \> \blue{then} \> p \> {\blue ;} \>
                        \mathtt{\blue{ while} \> b \> \{ p \} } 
                        \> \blue{ else} \> skip}$
                \item $\mathtt{\blue{ while} \> b \> \{ p \} } \> \blue{ ;} \> \mathtt{q} \equiv
                      \mathtt{\blue{if} \> b \> \blue{ then} \> p \> \blue{ ;}  \> \blue{ while} \> b \> \{ p \}
                      \> \blue{ ;} \> q
                      \> \blue{ else} \> q}$
                \item $\mathtt{\blue{ while} \> ff \> \{ p \} \> \blue{ ;} \> q } \equiv \mathtt{q}$
                \item $\mathtt{\blue{ while} \> tt \> \{ p \} } \equiv
                      \mathtt{\blue{ while} \> tt \> \{ q \} }$
        \end{itemize}
        Reflect on the differences between performing this exercise with the
        denotational, small-step, and big-step semantics.
\end{problem}

\begin{problem}
        Recall our big-step semantics and let us consider the program
        $\mathtt{\blue{ while} \> tt \> \{ p \} }$ together with a state
        $\sigma$. Although obvious, can you prove that there is no state
        $\sigma'$ such that $\mathtt{\blue{ while} \> tt \> \{ p \} }
        \Downarrow \sigma'$?  This can be problematic, because it is often
        cumbersome to prove the \emph{non-existence} of things. However perhaps the
        denotational semantics can help us in this quest.  What do you think?
\end{problem}

\section{Axiomatic Semantics}

Finally we lean over axiomatic semantics, which as you know has a more logical
nature and it is therefore better suited to study \emph{program correctness},
among other things.  This style of semantics puts the notion of proposition
(\ie\ condition) at center stage, which of course raises the question of which
logic to choose for writing and reasoning about such propositions.  We observed
that one does not actually need to choose a logic right from the outset, but
rather one makes basic assumptions about whatever logic is chosen.  One of
these assumptions is that every proposition $\Phi$ will correspond to a set
$\sem{\Phi} \subseteq \mathrm{State}_\bot$ (of elements that satisfy this
proposition). From this we worked out what a Hoare triple ought to mean
mathematically, \emph{viz.}
\[
         \{ \Phi \} \, \prog{p} \, \{ \Psi \} \qquad \text{ means } \qquad 
         \Big (\forall x \in \mathrm{State}_\bot. \> x \in \sem{\Phi} 
         \text{ entails } \sem{\prog{p}}(x) \in \sem{\Psi} \, \Big )
\]
Note that we are recurring to the previous denotational semantics to give a
meaning to Hoare triples.

\begin{problem}
        Argue \emph{informally} whether the following Hoare triples hold.
        \begin{itemize}
                \item $\{ \prog{tt} \} \> \> \prog{\blue{ while} \> \> tt \> \> skip} \> \> \{ \prog{ff} \}$
                \item $\{ \prog{tt} \} \> \> \prog{\blue{ if} \>  b \> \blue{ then} \> \> 
                        x:=2 \> \> \blue{ else} \> \> x:= 3} \> \> \{ \prog{x \geq 2} \}$
                \item $\{ \prog{x = a \wedge y = b} \} \> \>
                        \prog{x:= y \> \blue{ ;} \> y := x} \> \> \{ \prog{ x = b \wedge y = a }\}$
                \item $\{ \prog{x = a \wedge y = b} \} \> \>
                        \prog{aux := x \> \blue{ ;} \> 
                        x:= y \> \blue{ ;} \> y := aux} \> \> \{ \prog{ x = b \wedge y = a }\}$
        \end{itemize}
\end{problem}

We continued exploring the mathematical meaning of Hoare triples, and
among other things made the following observation.
\[
         \Big (\forall x \in \mathrm{State}_\bot. \> x \in \sem{\Phi} 
         \text{ entails } \sem{\prog{p}}(x) \in \sem{\Psi} \, \Big )
         \> \text{ iff } \>
         \sem{\Phi} \subseteq \sem{\prog{p}}^{-1}(\sem{\Psi})
\]
Although apparently vapid it is in fact quite profound. It suggests that we
study the validity of Hoare triples from the point of view of \emph{inverse
images}, via the denotational semantics, but also that the set
$\sem{\prog{p}}^{-1}(\sem{\Psi})$ has a prominent rÃ´le in this context. Indeed
the latter turns out to correspond precisely to the \emph{weakest
pre-condition} w.r.t. a program $\prog{p}$ and a post-condition $\Psi$.  

As E. Dijkstra asserted it is quite informative to determine the weakest
pre-condition related to a program $\prog{p}$ and a post-condition $\Psi$.
However it would be a hassle to calculate inverse images of some set directly.
The weakest pre-condition semantics we saw in the lectures circumvents this
problem (among other things). It is detailed in Figure~\ref{fig:ax1} (note our
assumption about the logic having \emph{infinite} conjunctions, negation, and
disjunctions).

\begin{figure}[h]
\begin{minipage}{1\textwidth}
\begin{flalign*}
                \mathrm{wp}\,(\prog{x : = e}, \Phi) & = \Phi[\prog{e}/\prog{x}]
                \\[5pt]
                %
                \mathrm{wp}\,(\prog{p} \> \blue{ ;} \> \prog{q}, \Phi) & 
                = \mathrm{wp} \, (\prog{p}, \mathrm{wp} \, (\prog{q}, \Phi))  
                \\[5pt]
                %
                \mathrm{wp}\,({\mathtt{\blue{ if} \> b \> \blue{ then} \> p \> \blue{ else} \> q}}, \Phi)
                & 
                =
                \prog{b} \wedge \mathrm{wp}\, (\prog{p},\Phi) \, \vee \,
                \prog{\neg b} \wedge \mathrm{wp} \, (\prog{q}, \Phi)
                \\[5pt]
                \mathrm{wp} \, ({\mathtt{\blue{ while} \> b \> \blue{ do} \> \{ \> p \> \}} }, \Phi)
                & = \bigwedge_{n \in \Nats} \Psi_n
                \\[10pt]
        \Psi_0 & = \prog{tt} \\
        \Psi_{n+1} & = \neg \prog{b} \wedge \Phi \, \vee \, \prog{b} \wedge 
        \mathrm{wp} \, (\prog{p}, \Psi_n)
\end{flalign*}
\end{minipage}
\caption{A weakest pre-condition semantics for the while-language.}
\label{fig:ax1}
\end{figure}

Let us try this new semantics with a series of very simple examples.
\begin{problem}
        \label{prob:weakest}
 Calculate the weakest pre-conditions w.r.t. the following pairs.
 \begin{itemize}
         \item $(\prog{x := y}, \>  \prog{x} \geq 1)$
         \item $(\prog{\blue{ if} \>  b \> \blue{ then} \> \> 
                 x:=2 \> \> \blue{ else} \> \> x:= 3}, \> \prog{x \geq 2})$
         \item $(\prog{x:= y \> \blue{ ;} \> y := x}, \> \prog{ x = b \wedge y = a })$
         \item $(\prog{ aux := x \blue{ ;} \> 
                 x:= y \> \blue{ ;} \> y := aux}, \> \prog{ x = b \wedge y = a })$
 \end{itemize}
 Go to your old material about `algorithms and complexity' and check whether you can
 prove the weakest pre-conditions of other pairs.
\end{problem}

\begin{problem}
        \label{prob:tt}
  Prove that $\mathrm{wp} \, (\prog{p}, \prog{tt}) \equiv \prog{tt}$ for every
  program $\prog{p}$.
\end{problem}

Right, following our traditions we should connect this new semantics to the
previous ones (\ie\ we should be able to prove that they all `agree' with each
other). And indeed we saw in the lectures that the following equation holds for
every program $\prog{p}$ and condition $\Phi$.
\begin{align}
        \label{eq:wp}
        \sem{\mathrm{wp} \, (\prog{p}, \Phi)} = \sem{\prog{p}}^{-1}(\sem{\Phi})
\end{align}
As mentioned in the lectures, the respective proof can be neatly established
via Domain theory. Unfortunately the techniques involved are a bit more
advanced than the ones addressed in the lectures :-(.

\begin{problem}
        Resort to Equation~\eqref{eq:wp} to prove the following equivalences.
    \begin{itemize}
                \item $\mathrm{wp} \, (\prog{p}, \prog{tt}) \equiv \prog{tt}$
                \item $\mathrm{wp} \, (\prog{p}, \Phi \wedge \Psi )
                \equiv \mathrm{wp} \, (\prog{p}, \Phi) \wedge 
                \mathrm{wp} \, (\prog{p}, \Psi )$
   \end{itemize}
   What are differences between showing the first equivalence in this problem
   and in Problem~\eqref{prob:tt}? Can you prove the second equivalence without
   recurring to Equation~\eqref{eq:wp}?
\end{problem}

We also saw how to generate a calculus from this pre-condition semantics for
showing the validity of Hoare triples. This calculus is prominently simple: in
fact it only contains one rule, \emph{viz.}
\[
                \infer{\vdash \{ \Phi \} \, \prog{p} \, \{ \Psi \}}
                { \vdash \Phi \rightarrow \mathrm{wp} \, (\prog{p}, \Psi) }
\]

\begin{problem}
        Prove that the calculus is sound (\ie\ correct) and relatively complete
        (\ie\ we can prove that every valid Hoare triple is valid if the underlying
        logic is complete).
\end{problem}

Later on we observed that although interesting the calculus is a bit `too
rigid' to prove the validity of Hoare triples: indeed the fact that it is
strictly based on weakest pre-conditions and infinite conjunctions makes it
less amenable to practical uses. This brings us back to old friends, namely the
Hoare calculus that you saw in `algorithms and complexity' and which is now
detailed in Figure~\ref{fig:Hoare}.

\begin{figure}[h]
\begin{minipage}{1\textwidth}
\begin{flalign*}
                \infer{ \vdash_H \{ \Phi \} \> \prog{skip} \> \{ \Phi \} }{}
                \hspace{2.5cm}
                \infer{ \vdash_H \{ \Phi[\prog{e}/\prog{x}] \} \> \prog{ x : = e } \>
                \{ \Phi \} }{}
\end{flalign*}
\\[-30pt]
\begin{flalign*}
                \infer { \vdash_H \{ \Phi \} \> \prog{p \> \blue{ ;} \> q} \> \{ \Xi \} }{
                        \vdash_H \{ \Phi \} \> \prog{p} \> \{ \Psi \}
                        \qquad
                        \vdash_H \{ \Psi \} \> \prog{q} \> \{ \Xi \}
                }
                \hspace{2.5cm}
                \infer{
                        \vdash_H \{ \Phi \} \> \prog{\blue{ while}} \> \prog{b} \>
                        \{ \> \prog{p} \> \} \> 
                        \{ \neg \prog{b} \wedge \Phi \}
                }{
                        \vdash_H
                        \{ \Phi \wedge \prog{b} \} \>  \prog{p}  \> \{ \Phi \}
                }
\end{flalign*}
\\[-30pt]
\begin{flalign*}
                \infer {
                        \vdash_H \{ \Phi \} \> \prog{\blue{ if} \> b}
                        \> \prog{\blue{ then}} \>
                        \prog{p} \> \prog{\blue{ else}} \> \prog{q}
                        \> \{ \Psi \}
                }{
                        \vdash_H \{ \prog{b} \wedge \Phi \} \> \prog{p} \> \{ \Psi \}
                        \qquad
                        \vdash_H \{ \prog{\neg b} \wedge \Phi \} \> \prog{q} \> \{ \Psi \}
                }
\end{flalign*}
\\[-30pt]
\begin{flalign*}
                \infer{ \vdash_H \{ \Phi \} \> \prog{p} \> \{ \Psi \} }{
                        \vdash \Phi \rightarrow \Psi
                        \quad
                        \vdash_H \{ \Psi \} \> \prog{p} \> \{ \Xi \}
                        \quad
                        \vdash \Xi \rightarrow \Omega
                }
\end{flalign*}
\end{minipage}
\caption{Hoare calculus for our while-language.}
\label{fig:Hoare}
\end{figure}

\begin{problem}
        Recall Problem~\eqref{prob:weakest} where we derived weakest
        pre-conditions for different pairs. Show now via Hoare calculus that
        these weakest pre-conditions together with the respective pairs form
        valid Hoare triples.  Try then to establish the validity of the
        following Hoare triple.
        \[
                 \{ \prog{x = n \geq 0 \wedge y = 1} \} \> \> \prog{fact} \> \>
                \{ \prog{y = n!} \}
        \]
        ${\small \prog{fact} = \prog{\blue{while} \> x > 0 \> \{ y :=
        x \times y \> {\blue ;} \> x := x - 1 \} } }$.
        Reflect on the differences between trying to prove the valid of Hoare triples
        w.r.t. weakest pre-condition calculus and Hoare calculus.
\end{problem}

Well now that we have our old friend back, it makes sense to prove that it is
correct, a fact that we were not able to formulate much less prove in
`algorithms and complexity'.
\begin{problem}
        Prove by induction (on the depth of derivation trees) that the Hoare
        calculus is sound, \ie\ that the following implication holds for every
        program $\prog{p}$ and conditions $\Phi$ and $\Psi$.  \[
                \vdash_H \{ \Phi \} \, \prog{p} \, \{ \Psi \}
                \text{ entails }
                \sem{\Phi} \subseteq \sem{\prog{p}}^{-1}(\sem{\Psi})
        \]
        You can skip the case of while-loops, for it is much harder to prove
        than the other cases. Note however that it can be neatly proved via
        Domain theory.
\end{problem}

Finally another thing we saw in the lectures is that for every program
$\prog{p}$ and condition $\Phi$ we were able to prove $\vdash_H \{ \mathrm{wp}
\, (\prog{p}, \Phi) \} \> \prog{p} \> \{ \Psi \}$.

\begin{problem}
        Use this last result to prove the relative completeness of the Hoare calculus
        from the relative completeness of the weakest pre-condition calculus.
\end{problem}
\end{document}


